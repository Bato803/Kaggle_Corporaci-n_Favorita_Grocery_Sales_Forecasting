{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model Construction and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Standardization-of-data\" data-toc-modified-id=\"Standardization-of-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Standardization of data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-set\" data-toc-modified-id=\"Training-set-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Training set</a></span></li><li><span><a href=\"#Validation-and-test-set\" data-toc-modified-id=\"Validation-and-test-set-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Validation and test set</a></span></li></ul></li><li><span><a href=\"#Metrics\" data-toc-modified-id=\"Metrics-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Metrics</a></span></li><li><span><a href=\"#Random-Forest-Regressor\" data-toc-modified-id=\"Random-Forest-Regressor-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Random Forest Regressor</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grid-Search-to-find-the-best-RF-hyper-parameters\" data-toc-modified-id=\"Grid-Search-to-find-the-best-RF-hyper-parameters-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Grid Search to find the best RF hyper-parameters</a></span></li><li><span><a href=\"#Train-RF-to-predict-one-day-at-a-time\" data-toc-modified-id=\"Train-RF-to-predict-one-day-at-a-time-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Train RF to predict one day at a time</a></span></li><li><span><a href=\"#RF-with-feature-selection\" data-toc-modified-id=\"RF-with-feature-selection-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>RF with feature selection</a></span></li></ul></li><li><span><a href=\"#LSTM\" data-toc-modified-id=\"LSTM-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>LSTM</a></span><ul class=\"toc-item\"><li><span><a href=\"#Building-Model\" data-toc-modified-id=\"Building-Model-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Building Model</a></span></li><li><span><a href=\"#Training-Model\" data-toc-modified-id=\"Training-Model-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Training Model</a></span></li></ul></li><li><span><a href=\"#GRU\" data-toc-modified-id=\"GRU-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>GRU</a></span></li><li><span><a href=\"#Stacked-LSTM\" data-toc-modified-id=\"Stacked-LSTM-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Stacked LSTM</a></span></li><li><span><a href=\"#Submission\" data-toc-modified-id=\"Submission-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Submission</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/Bato/anaconda/envs/aind-dog/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/Bato/anaconda/envs/aind-dog/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "%matplotlib inline\n",
    "default_stdout = sys.stdout\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# Sklearn \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error,r2_score,explained_variance_score\n",
    "from sklearn.feature_selection import mutual_info_regression,SelectKBest\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train = feather.read_dataframe(\"./data/df_x_train.feather\")\n",
    "Y_train = feather.read_dataframe(\"./data/df_y_train.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_val = feather.read_dataframe(\"./data/X_val.feather\")\n",
    "y_val = feather.read_dataframe(\"./data/y_val.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_test = feather.read_dataframe(\"./data/X_test.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weights = np.load(\"./data/weights.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Standardization of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_scaler = StandardScaler()\n",
    "train_scaler.fit(X_train[:300])\n",
    "X_train = train_scaler.transform(X_train)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "Y_train = Y_train.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "val_scaler = StandardScaler()\n",
    "val_scaler.fit(x_val)\n",
    "test_scaler = StandardScaler()\n",
    "test_scaler.fit(x_test)\n",
    "\n",
    "x_val = val_scaler.transform(x_val)\n",
    "x_val = x_val.reshape((x_val.shape[0],1,x_val.shape[1]))\n",
    "x_test = val_scaler.transform(x_test)\n",
    "x_test = x_test.reshape((x_test.shape[0],1,x_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def NWRMSLE(y_true, y_pred, weights, if_list=True):\n",
    "    \"\"\"\n",
    "    y_pred: a list of prediction of length 16. \n",
    "    \"\"\"\n",
    "    if if_list:\n",
    "        error = (y_true - np.array(y_pred).squeeze(axis=2).transpose())**2\n",
    "    else:\n",
    "        error = (y_true-y_pred)**2\n",
    "    \n",
    "    normalized_weighted_error = error.sum(axis=1)*weights\n",
    "    root_mean = np.sqrt(normalized_weighted_error.sum()/weights.sum()/16)\n",
    "    \n",
    "    return root_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Grid Search to find the best RF hyper-parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] max_depth=10, min_samples_split=10, n_estimators=50 .............\n",
      "[CV] max_depth=10, min_samples_split=10, n_estimators=50 .............\n",
      "[CV] max_depth=10, min_samples_split=10, n_estimators=50 .............\n",
      "[CV] max_depth=10, min_samples_split=10, n_estimators=80 .............\n"
     ]
    }
   ],
   "source": [
    "regr = RandomForestRegressor(n_jobs=-1)\n",
    "parameters = {'n_estimators':[50,80], 'min_samples_split':[10],\n",
    "              'max_depth':[10]}\n",
    "scoring = make_scorer(mean_squared_error)\n",
    "\n",
    "grid_search_obj = GridSearchCV(estimator=regr, param_grid=parameters, \n",
    "                               scoring=scoring, n_jobs=-1,verbose=3)\n",
    "\n",
    "grid_search_obj.fit(X_train[:,0,:], Y_train[:,:]-Y_train.mean())\n",
    "\n",
    "best_reg = grid_search_obj.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation from Random forest......................................\n",
      "The NWRMSLE is 0.6267107608443206\n",
      "The r2 score is 0.5355330073373146\n",
      "The explained variance is 0.5589823430786114\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_pred = best_reg.predict(x_val[:3000,0,:])+Y_train.mean()\n",
    "print(\"Results for validation from Random forest......................................\")\n",
    "print(\"The NWRMSLE is {0}\".format(NWRMSLE(y_val[:3000,:], rf_pred, weights[:3000], if_list=False)))\n",
    "print(\"The r2 score is {0}\".format(r2_score(y_val[:3000,:], rf_pred, sample_weight=weights[:3000])))\n",
    "print(\"The explained variance is {0}\".format(explained_variance_score(y_val[:3000],rf_pred,sample_weight=weights[:3000])))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train RF to predict one day at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_RF_one_day(best_reg, X, Y, w, xval, yval, xtest):\n",
    "    pred_val = []\n",
    "    pred_test = []\n",
    "    \n",
    "    parameters = best_reg.get_params()\n",
    "    n = parameters['n_estimators']\n",
    "    min_samples_split = parameters['min_samples_split']\n",
    "    max_depth = parameters['max_depth']\n",
    "    \n",
    "    for i in range(0, 3):\n",
    "        print(\"Predicting %d day \"%i)\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        y = Y[:,i] - Y[:,i].mean()\n",
    "        reg = RandomForestRegressor(n_estimators=n, min_samples_split=min_samples_split,\n",
    "                                   max_depth=max_depth,n_jobs=-1, verbose=1)\n",
    "        reg.fit(X, y, sample_weight=w)\n",
    "        \n",
    "        pred_val.append(reg.predict(xval)+Y[:,i].mean())\n",
    "        pred_test.append(reg.predict(xtest)+Y[:,i].mean())\n",
    "        \n",
    "    return pred_val, pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RF model to one day.............................................\n",
      "Predicting 0 day \n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1 day \n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2 day \n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time we used to train RF is 0.3534686009089152 minutes\n",
      "The NWRMSLE of validation set is 0.6209006065180679\n",
      "The r2 score of validation set with RF is 0.5812058871282513\n",
      "The explained variance is 0.5873526703771615\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Training RF model to one day.............................................\")\n",
    "start_time = time.time()\n",
    "pred_val, test_val = run_RF_one_day(best_reg, X_train[:3000,0,:], Y_train[:3000,:], weights[:3000],\n",
    "                                    x_val[:3000,0,:], y_val[:3000], x_test[:3000,0,:])\n",
    "print(\"The time we used to train RF is {0} minutes\".format((time.time()-start_time)/60))\n",
    "print(\"The NWRMSLE of validation set is {0}\".format(NWRMSLE(y_val[:3000,:3], np.array(pred_val).T, weights[:3000], if_list=False)))\n",
    "print(\"The r2 score of validation set with RF is {0}\".format(r2_score(y_val[:3000,:3], np.array(pred_val).T, sample_weight=weights[:3000])))\n",
    "print(\"The explained variance is {0}\".format(explained_variance_score(y_val[:3000,:3],np.array(pred_val).T,sample_weight=weights[:3000])))\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### RF with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def RF_feature_selection(best_reg, X, Y, w, xval, yval, xtest):\n",
    "    pred_val = []\n",
    "    pred_test = []\n",
    "    \n",
    "    parameters = best_reg.get_params()\n",
    "    n = parameters['n_estimators']\n",
    "    min_samples_split = parameters['min_samples_split']\n",
    "    max_depth = parameters['max_depth']\n",
    "    \n",
    "    for i in range(0, 3):\n",
    "        print(\"Predicting %d day \"%i)\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        y = Y[:,i] - Y[:,i].mean()\n",
    "        reg = RandomForestRegressor(n_estimators=n, min_samples_split=min_samples_split,\n",
    "                                   max_depth=max_depth,n_jobs=-1, verbose=1)\n",
    "        \n",
    "        reg_filter = SelectKBest(mutual_info_regression, k=300)\n",
    "        \n",
    "        new_reg = Pipeline([('filter', reg_filter),('reg', reg)])\n",
    "        new_reg.fit(X, y, sample_weight=w)\n",
    "        \n",
    "        pred_val.append(reg.predict(xval)+Y[:,i].mean())\n",
    "        pred_test.append(reg.predict(xtest)+Y[:,i].mean())\n",
    "        \n",
    "    return pred_val, pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RF model with feature selection.............................................\n",
      "Predicting 0 day \n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    7.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1 day \n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2 day \n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time we used to train RF is 0.3785074989000956 minutes\n",
      "The NWRMSLE of validation set is 0.6225411357043847\n",
      "The r2 score of validation set with RF is 0.5792547560972058\n",
      "The explained variance is 0.586899520077849\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training RF model with feature selection.............................................\")\n",
    "start_time = time.time()\n",
    "pred_val, test_val = run_RF_one_day(best_reg, X_train[:3000,0,:], Y_train[:3000,:], weights[:3000],\n",
    "                                    x_val[:3000,0,:], y_val[:3000], x_test[:3000,0,:])\n",
    "print(\"The time we used to train RF is {0} minutes\".format((time.time()-start_time)/60))\n",
    "print(\"The NWRMSLE of validation set is {0}\".format(NWRMSLE(y_val[:3000,:3], np.array(pred_val).T, weights[:3000], if_list=False)))\n",
    "print(\"The r2 score of validation set with RF is {0}\".format(r2_score(y_val[:3000,:3], np.array(pred_val).T, sample_weight=weights[:3000])))\n",
    "print(\"The explained variance is {0}\".format(explained_variance_score(y_val[:3000,:3],np.array(pred_val).T,sample_weight=weights[:3000])))\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_LSTM(X):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(X.shape[1],X.shape[2])))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(32))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(16))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_LSTM(X, Y, xval, yval, xtest, weights, epoches):\n",
    "    pred_val = []\n",
    "    pred_test = []\n",
    "    for i in range(0, 16):\n",
    "        print(\"Predicting %d day \"%i)\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        y = Y[:,i] - Y[:,i].mean()\n",
    "        model = build_LSTM(X)\n",
    "        opt = optimizers.Adam(lr=0.001)\n",
    "        model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
    "        \n",
    "        call_backs = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "            ReduceLROnPlateau(monitor='val_loss', patience=10, factor=0.1, \n",
    "                              verbose=1, mode='min')\n",
    "        ]\n",
    "        \n",
    "        model.fit(X, y, batch_size=1024, epochs=epoches, verbose=2,\n",
    "                 sample_weight=weights, validation_data=(xval, yval[:,i]-Y[:,i].mean()),\n",
    "                 callbacks=call_backs)\n",
    "        \n",
    "        pred_val.append(model.predict(xval)+Y[:,i].mean())\n",
    "        pred_test.append(model.predict(xtest)+Y[:,i].mean())\n",
    "        \n",
    "    return model, pred_val, pred_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Training LSTM model.............................................\")\n",
    "start_time = time.time()\n",
    "model, pred_val, test_val = run_LSTM(X_train, Y_train, x_val, y_val, \n",
    "                                     x_test, weights, 1000)\n",
    "print(\"The time we used to train LSTM network is {0} minutes\".format((time.time()-start_time)/60))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NWRMSLE of validation set is 0.5886397111899362\n",
      "The r2 score of validation set with LSTM is 0.6966021563558484\n",
      "The explained variance is 0.6998464651219788\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The NWRMSLE of validation set is {0}\".format(NWRMSLE(y_val, lstm_pred_val, weights[:170810])))\n",
    "print(\"The r2 score of validation set with LSTM is {0}\".format(r2_score(y_val, np.array(lstm_pred_val)[:,:,0].T, sample_weight=weights[:170810])))\n",
    "print(\"The explained variance is {0}\".format(explained_variance_score(y_val,np.array(lstm_pred_val)[:,:,0].T,sample_weight=weights[:170810])))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sys.stdout = default_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_GRU(X):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(256, input_shape=(X.shape[1],X.shape[2])))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(32))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(16))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_GRU(X, Y, xval, yval, xtest, weights, epoches):\n",
    "    pred_val = []\n",
    "    pred_test = []\n",
    "    for i in range(0, 16):\n",
    "        print(\"Predicting %d day \"%i)\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        y = Y[:,i] - Y[:,i].mean()\n",
    "        model = build_GRU(X)\n",
    "        opt = optimizers.Adam(lr=0.001)\n",
    "        model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
    "        \n",
    "        call_backs = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "            ReduceLROnPlateau(monitor='val_loss', patience=10, factor=0.1, \n",
    "                              verbose=1, mode='min')\n",
    "        ]\n",
    "        \n",
    "        model.fit(X, y, batch_size=1024, epochs=epoches, verbose=2,\n",
    "                 sample_weight=weights, validation_data=(xval, yval[:,i]-Y[:,i].mean()),\n",
    "                 callbacks=call_backs)\n",
    "        \n",
    "        pred_val.append(model.predict(xval)+Y[:,i].mean())\n",
    "        pred_test.append(model.predict(xtest)+Y[:,i].mean())\n",
    "        \n",
    "    return model, pred_val, pred_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Training GRU model.............................................\")\n",
    "start_time = time.time()\n",
    "model, pred_val, test_val = run_GRU(X_train, Y_train, x_val, y_val, \n",
    "                                     x_test, weights, 1000)\n",
    "print(\"The time we used to train GRU network is {0} minutes\".format((time.time()-start_time)/60))\n",
    "print(\"The NWRMSLE of validation set is {0}\".format(NWRMSLE(y_val, pred_val, weights)))\n",
    "print(\"The r2 score of validation set with GRU is {0}\".format(r2_score(y_val, pred_val, sample_weight=weights)))\n",
    "print(\"The explained variance is {0}\".format(explained_variance_score(y_val,pred_val,sample_weight=weights)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_stackedLSTM(X):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(X.shape[1],X.shape[2]),\n",
    "             return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(LSTM(128))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(32))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(16))\n",
    "    model.add(ELU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_stackedLSTM(X, Y, xval, yval, xtest, weights, epoches):\n",
    "    pred_val = []\n",
    "    pred_test = []\n",
    "    for i in range(0, 16):\n",
    "        print(\"Predicting %d day \"%i)\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        y = Y[:,i] - Y[:,i].mean()\n",
    "        model = build_stackedLSTM(X)\n",
    "        opt = optimizers.Adam(lr=0.001)\n",
    "        model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
    "        \n",
    "        call_backs = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "            ReduceLROnPlateau(monitor='val_loss', patience=10, factor=0.1, \n",
    "                              verbose=1, mode='min')\n",
    "        ]\n",
    "        \n",
    "        model.fit(X, y, batch_size=1024, epochs=epoches, verbose=2,\n",
    "                 sample_weight=weights, validation_data=(xval, yval[:,i]-Y[:,i].mean()),\n",
    "                 callbacks=call_backs)\n",
    "        \n",
    "        pred_val.append(model.predict(xval)+Y[:,i].mean())\n",
    "        pred_test.append(model.predict(xtest)+Y[:,i].mean())\n",
    "        \n",
    "    return model, pred_val, pred_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Training stackedLSTM model.............................................\")\n",
    "start_time = time.time()\n",
    "model, pred_val, test_val = run_stackedLSTM(X_train, Y_train, x_val, y_val, \n",
    "                                     x_test, weights, 1000)\n",
    "print(\"The time we used to train stackedLSTM network is {0} minutes\".format((time.time()-start_time)/60))\n",
    "print(\"The NWRMSLE of validation set is {0}\".format(NWRMSLE(y_val, pred_val, weights)))\n",
    "print(\"The r2 score of validation set with stacked LSTM is {0}\".format(r2_score(y_val, pred_val, sample_weight=weights)))\n",
    "print(\"The explained variance is {0}\".format(explained_variance_score(y_val,pred_val,sample_weight=weights)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "def create_submission(df_2017, df_test):\n",
    "    y_test = np.load(\"./res/lstm_pred_test_1.npy\")\n",
    "    y_test = y_test.squeeze(axis=2).transpose()\n",
    "    df_preds = pd.DataFrame(y_test, index=df_2017.index,\n",
    "                           columns=pd.date_range(\"2017-08-16\", periods=16)).stack().to_frame(\"unit_sales\")\n",
    "\n",
    "    df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "    \n",
    "    submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "    submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "    submission.to_csv('./submission/lstm_pred_test_1.csv', float_format='%.4f', index=None)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_raw = feather.read_dataframe(\"./data/train_raw.feather\")\n",
    "train_raw['unit_sales'] = train_raw['unit_sales'].apply(func=lambda x:np.log1p(x) if float(x)>0 else 0)\n",
    "df_2017 = train_raw.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"./data/test.csv\",\n",
    "    converters={\"onpromotion\": lambda p:int(p==True)},\n",
    "    parse_dates=[\"date\"]\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_submission(df_2017, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {
    "height": "822px",
    "left": "0px",
    "right": "1210.23px",
    "top": "67px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
